{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0d52017-d78f-4e6d-b21e-c6a11200685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7438455afdf4d14ad8312ef32a3a157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"unsloth/gemma-2-9b-it\", use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"unsloth/gemma-2-9b-it\",\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "text_gen = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033c6cb8-0afe-4f31-8243-ba598502f76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name sbunlp/fabert. Creating a new one with mean pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at sbunlp/fabert and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "embedding_name = 'sbunlp/fabert'\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "660ab25c-8a67-4812-ba70-81bde9b31fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=text_gen)\n",
    "\n",
    "def apply_chat_template_and_response(prompt):\n",
    "    messages = [\n",
    "    {'role': 'user', 'content': prompt}\n",
    "    ]\n",
    "\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False\n",
    "    )\n",
    "\n",
    "    return llm.invoke(text).replace(text, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee4844f-2b15-434e-882c-3162a2b93627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "من Gemma هستم، یک مدل زبان بزرگ باز که توسط Google DeepMind آموزش داده شده‌ام.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(apply_chat_template_and_response(\"اسمت چیه؟\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c5fb5c6-0bcc-4758-a16e-c694d95dcb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"هر کس تو را به پایین نگاه می برد، تو را به بالا بکش.\"\n",
      "\n",
      "**Translation:** \"Whoever looks down on you, pull them up.\"\n",
      "\n",
      "\n",
      "This quote emphasizes self-belief and resilience. It encourages you to rise above negativity and help others along the way. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "response_from_model = apply_chat_template_and_response(\"Give me an inspirational quote in persian\")\n",
    "parsed_response = parser.parse(response_from_model)\n",
    "print(parsed_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac156441-3f69-4f3a-b9eb-6c00048415ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are a helpful and knowledgeable AI assistant. Use only the information retrieved from the documents to answer the user\\'s question in Persian (Farsi). If the answer is not found in the retrieved context, respond with: \"متاسفانه اطلاعاتی در این مورد ندارم.\" Do not use your own knowledge beyond the provided context. Be accurate, clear, and polite. Never mention the documents or the retrieval process in your response. Just respond naturally in Persian.\\nContext: Here is some context\\n\\nQuestion: Here is a question\\n\\nAnswer:\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are a helpful and knowledgeable AI assistant. Use only the information retrieved from the documents to answer the user's question in Persian (Farsi). If the answer is not found in the retrieved context, respond with: \"متاسفانه اطلاعاتی در این مورد ندارم.\" Do not use your own knowledge beyond the provided context. Be accurate, clear, and polite. Never mention the documents or the retrieval process in your response. Just respond naturally in Persian.\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Here is some context\", question=\"Here is a question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec4c80a-e2ba-4c8d-897d-3ac97ca8314f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "اسم تو علیرضا هست.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"من علیرضا هستم و تهران زندگی میکنم.\"\n",
    "formatted_prompt = prompt.format(context = context, question=\"اسم من چیه؟\")\n",
    "response_from_model = apply_chat_template_and_response(formatted_prompt)\n",
    "parsed_response = parser.parse(response_from_model)\n",
    "print(parsed_response.replace(formatted_prompt, \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e0d02c1-100e-4ccd-9d94-12f975477887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"my_pdf.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1063185a-bbf7-4282-9145-e51946c9cdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=256)\n",
    "text_documents = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d26049ed-beca-4748-b185-1ddc77d01d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 0, 'page_label': '1'}, page_content='1-مقدمه ..................................................................................................... 2 \\n2- گام اول: درک خواسته های   کسب و کار یا Business Understanding ................... 5 \\n3- گام دوم: درک داده هایا  Data Understanding .............................................. 7 \\n4- گام سوم: آماده سازی   داده ها  یا  Data Preparation ........................................ 11 \\n5- گام چهارم: مدل سازی  یا  Modeling ............................................................ 17 \\n6- گام پنجم: ارزیابی  یا    Evaluating ................................................................ 44 \\n7- گام ششم: بکارگیری   یا   Deployment .......................................................... 53'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 1, 'page_label': '2'}, page_content='1- مقدمه \\nشرح متدولوژی انتخابی:  \\nCRSIP-DM   مخفف عبارت Cross-industry standard process for data mining و به معنی\\n«\\nاست که رویکردهای عمومی متخصصان داده کاوی را تشریح میکند. این روش از پرکاربردترین مدل های  \\nتحلیلی است. \\nگروهی از شرکت های اروپایی در دهه  1990 برای اولین بار از فرایند کریسپ برای انجام پروژههای داده کاوی  \\nاستفاده کردند. این فرایند دارای  6  محله اصلی است. این مراحل متوالی، از درک نیازهای اصلی کسب و کار\\nشروع شده و با ارائه راهکارهای مفید به پایان می رسد . \\nهمان طور که اشاره کردیم، روش  crisp dm، الگوی فرآیند محور داده کاوی است که راهکاری نظاممند، \\nمفید و کاربردی برای ابعاد داده و همچنین خوشه بندی داده ها ارائه می کند. از آنجا که خوشه بندی از مباحث  \\nمهم و اساسی در داده کاوی محسوب می شود، خوب است به خوشه بندی نیز اشاره مختصری داشته باشیم.  \\nخوشه Cluster) به مجموعهای از داده های شبیه به هم گفته می شود و خوشه بندی فرآیندی است که به  \\nکمک آن می توانید مجموعه ای از اشیا را به گروه های مجزا تفکیک کنید .'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 1, 'page_label': '2'}, page_content='مهم و اساسی در داده کاوی محسوب می شود، خوب است به خوشه بندی نیز اشاره مختصری داشته باشیم.  \\nخوشه Cluster) به مجموعهای از داده های شبیه به هم گفته می شود و خوشه بندی فرآیندی است که به  \\nکمک آن می توانید مجموعه ای از اشیا را به گروه های مجزا تفکیک کنید . \\nبرای انجام خوشه بندی، داده ها را به خوشه های مختلف تقسیم می کنند. بنابراین، شباهت میان داده های درون  \\nهر خوشه به حداکثر و شباهت میان داده های درون خوشه های متفاوت به حداقل می رسد. در طبقه بندی، به  \\nهر داده یک طبقه یا کلاس از پیش تعیین شده اختصاص می یابد. در حالی که در خوشه بندی هیچ اطلاعی از  \\nکلاس های موجود درون داده ها وجود ندارد و خوشه ها از داده ها استخراج می شوند. خوشه بندی را می توانیم  \\nبه عنوان مهم ترین مساله در یادگیری بدون نظارت در نظر بگیریم. \\nمراحل متدولوژی CRISP  : \\n1) فهم کسب و کار Business Understanding) \\nدر این  مرحله،  یک  متخصص علم داده بایستی  کسب و کاری  که می خواهد   بر رو ی  آن پروژه داده کاوی  انجام  \\nدهد را به خوبی  بشناسد. در مرحله ی  فهم کسب و کار، بای ستی  زوایای  مختلف آن کسب و کار، محدودیت ها،'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 1, 'page_label': '2'}, page_content='1) فهم کسب و کار Business Understanding) \\nدر این  مرحله،  یک  متخصص علم داده بایستی  کسب و کاری  که می خواهد   بر رو ی  آن پروژه داده کاوی  انجام  \\nدهد را به خوبی  بشناسد. در مرحله ی  فهم کسب و کار، بای ستی  زوایای  مختلف آن کسب و کار، محدودیت ها،  \\nشرایط  موجود و اهداف آن کسب و کار از پروژه یا پروژه های جاری را بررس ی نمود. این  مرحله ذهن متخصص'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 2, 'page_label': '3'}, page_content='علم داده را برای   کار بر رو ی  پروژه آماده می کند   و به او اجازه می دهد   تا با شناخت بیشتر  و بهتر به سراغ مراحل  \\nبعد ی  برود. در این  مرحله،  ی ک  متخصص علم داده می تواند   تا حدودی  به کسب و کارِ موجود مسلط شده و  \\nفهم خود را از آن کسب و کار تا حد ممکن بالا ببرد. \\n2) فهم دادهها Data Understanding) \\nدر  مرحله ی  فهم داده ها، متخصص علم داده، به سراغ داده های  موجود کسب و کار رفته آن را برای  شروع پروژه  \\nبررس ی  می کند . در این  مرحله، عملیاتی  مانندیز  اکتشافی  داده ها – EDA» و ساخت گزارشهای  اولی ه  از  \\nداده ها می تواند   بسیار  کمک کننده باشد. با فهم داده ها و درک  ابعاد و ویژگی های  مختلف آن، می توان   ایده های  \\nمختلف را مطرح کرد و ساختار اصلی  پروژه را تعیین  نمود. در این  مرحله می توان  کی فی ت داده ها را نی ز ارزیابی   \\nکرد و در صورت نامناسب بودن داده ها، با مشورت و مشارکت قسمت های  مختلف کسب و کار، این  داده ها را  \\nبهبود بخشید . \\n3) آمادهسازی داده ها Data Preparation) \\nبعد  از فهم کسب و کار و فهم داده ها، حال می توان   داده ها را آماده ی  تحلیل   و مدل سازی   کرد. اگر دوره ی  پی ش'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 2, 'page_label': '3'}, page_content='بهبود بخشید . \\n3) آمادهسازی داده ها Data Preparation) \\nبعد  از فهم کسب و کار و فهم داده ها، حال می توان   داده ها را آماده ی  تحلیل   و مدل سازی   کرد. اگر دوره ی  پی ش   \\nپردازش داده ها را در چیستیو  مطالعه کرده باش ید،  احتمالاً به سادگی  می توانید   این  مرحله را درک کنید . در  \\nاین  مرحله، داده های  کثی ف،   تمیز   م ی شوند   و داده ها به صورت ساختاری،   برای   مرحله ی  بعد ی   آماده سازی \\nمی شوند . در این  مرحله همچنین  م ی توان  مجموعه داده های  مختلف را با  یکد یگر  ترکی ب  کرد تا به مجموعه  \\nداده ی بهتر و با کی فیت تری  رس ید . \\n4) مدلسازی Modeling) \\nبسته  به ای نکه  مسئله ی  شما چه نوع مسئله ایست  در این  مرحله بایستی  از الگوریتم ها  و روش های  مخصوص به  \\nخود استفاده کنید . مثلاً اگر مسئله ی  شما طبقه بند ی  داده هاست، بایستی  از الگوریتمهای  طبقه بند ی  برای   \\nیادگیری   استفاده کن ید   و  یا   اگر مسئله ی  شما در دسته ی  خوشه بند ی  قرار م ی گی رد،  م ی توانید   یکی  از  \\nالگوریتم های  خوشهبند ی  را برای  پروژه ی  خود مورد استفاده قرار دهید . البته در  یک  پروژه ی  داده کاوی،  ممکن'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 2, 'page_label': '3'}, page_content='یادگیری   استفاده کن ید   و  یا   اگر مسئله ی  شما در دسته ی  خوشه بند ی  قرار م ی گی رد،  م ی توانید   یکی  از  \\nالگوریتم های  خوشهبند ی  را برای  پروژه ی  خود مورد استفاده قرار دهید . البته در  یک  پروژه ی  داده کاوی،  ممکن  \\nاست مسائل مختلف و ترکیب ی وجود داشته باشد که نیاز  به عملیات پیچیده تری  جهت مدل سازی  دارند . \\n5) ارزیابی Evaluation) \\nچیزی  که قابل ارزیابی   نباشد، بهبود پیدا  نمی کند . اگر در مراحل قبلی   داده ها را آماده کردید   و مدلی   ساختید،  \\nبایستی  بتوانید   مدلِ خود را ارزیابی  کنید . این  ارزیابی  بستگ ی  به مدلِ انتخابی  دارد. برای  مثال اگر مسئله ی'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 3, 'page_label': '4'}, page_content='شما طبقهبند ی  بود، م ی توانید   از روش های  ارزیابی  الگوری تمهای  طبقه بند ی  استفاده کنید . طبیعتاً  اگر مدلِ  \\nشما به اندازهی  کافی  کیفیت   نداشت، بهتر است به مراحل قبلی  بازگرید   و مدل  یا  داده ها  یا   روش های  آماده سازی  \\nداده هایتان را بهبود بخشیده   و مجدداً ارزیابی  را انجام دهی د . \\n6) پیادهسازی و انتشار Deploy) \\nدر نهایت، بایستی  نرم افزار ی  توسعه دهید  تا کاربران بتوانند از زحمات شما استفاده کنند. این مرحله، معمولاً  \\nبا کمک مهندس ین نرم افزار و برنامه نویسان انجام م ی شود.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 4, 'page_label': '5'}, page_content='2- گام اول: درک خواسته های کسب و کار یا  Business Understanding \\nیکی از مهمترین موضوعات در دنیای مدرن، توجه به امنیت در کلیه حوزه های زندگی است. مسئله امنیت  \\nاطلاعات در شرکت ها به ویژه بخش های مرتبط با اطلاعات حیاتی یک موضوع پررنگ و چالش برانگیز است. \\nاطلاعات حیاتی ممکن است به وسیله عوامل داخلی و خارجی، به صورت خواسته یا ناخواسته به سرقت برود  \\nو خسارتهای جبران ناپذیری را به ارمغان بیاورد.  \\nامنیت اطلاعات به منظور حفظ و نگهداری اطلاعات از فعالیتهایی هم چون جلوگیری از دسترسی غیرمجاز،  \\nاستفاده، خواندن، تغییر، دستکاری و یا افشا کردن اطلاعات تا تعریف ساختار صحیح مدیریت دسترسی، استفاده  \\nصحیح و روالمند از داده های سازمان تشکیل می شود و  موجب  کنترل   محرمانگی،  یکپارچگی  و   در   دسترس   \\nبودن  داده ها در سازمان خواهد  شد . \\nبدین ترتیب سازمان  ها ملزم هستند به منظور جلوگیری از سرقت اطلاعات نسبت به اجرا استانداردهای امنیتی  \\nاقدام کنند. با پیاده سازی راهبردهای امنیتی ضمن ایجاد سیاستهای کنترلی، امنیتی و محافظت از داده ها  \\nسبب شکل گیری راهبرد و تکنیک های خاص در راستای افزایش قدرت تصمیم گیری، رقابت برتر، شکل'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 4, 'page_label': '5'}, page_content='اقدام کنند. با پیاده سازی راهبردهای امنیتی ضمن ایجاد سیاستهای کنترلی، امنیتی و محافظت از داده ها  \\nسبب شکل گیری راهبرد و تکنیک های خاص در راستای افزایش قدرت تصمیم گیری، رقابت برتر، شکل  \\nگیری اعتماد نزد اعتماد و استفاده از سیستمهای مدیریت امنیت اطلاعات ISMS در سازمانها می گردد.  \\nهدف از ایجاد امنیت اطلاعات حفظ و نگهداری از داده های حیاتی از فعالیت هایی نظیر افشاء، دسترسی  \\nغیرمجاز، خواندن، دستکاری، تغییر و سوء استفاده است. در واقع امنیت اطلاعات در یکپارچگی، کنترل  \\nمحرمانگی و در دسترس بودن اطلاعات برای کارمندان حائز اهمیت است.  \\nبه طور مختصر وجود هرگونه مشکل امنیتی سبب تحمیل خسارتهای جبران ناپذیر به سازمان می شود. از  \\nسری خسارتهای مشکل امنیتی در سازمان می توان به موارد ذیل اشاره کرد:  \\n• کاهش اعتماد مشتریان، سرمایه گذاران و کارمندان  \\n• کاهش چشمگیر مشتریان سازمان  \\n• از دست رفتن اعتبار سازمان در میان رقبا  \\n• افزایش هزینه های سازمانی  \\n• کاهش سطح بهره وری و درآمد سازمان'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 5, 'page_label': '6'}, page_content='واژه امنیت اطلاعات تنها برای یک الی چند دستگاه کاربرد ندارد، بلکه برای کلیه سطوح سازمانی در نظر گرفته\\nمی شود. به عبارتی ضرورت دارد تمهیداتی در نظر گرفته شود که از بدو ورود اطلاعات به صورت سخت افزاری  \\nو نرم افزاری الی محل قرار گیری، ذخیره و بایگانی آن کلیه تدابیر امنیتی در راستای مقابله با تهدیدات مختلف  \\nشکل بگیرد. \\nراهکار بسیاری از سازمان ها استفاده از گران قیمتترین فایروال ها و برنامه های ضد باج افزار و آنتی ویروس ها  \\nمی باشد اما شایان ذکر هست که فقط داشتن این ابزارهای امنیتی کافی نیست و این ابزارها زمانی سازنده و  \\nمفید هستند که با شناخت و تحلیل های دقیق امنیتی، استفاده از روال های استاندارد در به کارگیری و کنترل  \\nسیستمهای امنیتی و به روزرسانی مداوم این سیستم ها صورت بگیرد.  \\nاین پروژه جهت  بررسی نقاط ضعف  امینت سایبری  یک سازمان که در حوزه کسب و کار اینترنتی فعالیت دارد،  \\nانجام می شود. پس بنابراین هدف ما در این پروژه بررسی وضعیت امنیت سازمان، شناسایی نقاط ضعف و  \\nاطلاع به سازمان جهت برطرف سازی نقاط ضعف امنیتی می باشد.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 5, 'page_label': '6'}, page_content='این پروژه جهت  بررسی نقاط ضعف  امینت سایبری  یک سازمان که در حوزه کسب و کار اینترنتی فعالیت دارد،  \\nانجام می شود. پس بنابراین هدف ما در این پروژه بررسی وضعیت امنیت سازمان، شناسایی نقاط ضعف و  \\nاطلاع به سازمان جهت برطرف سازی نقاط ضعف امنیتی می باشد. \\nسازمان مورد نظر ما به طور چشم گیری مورد حملات امنیتی مختلف قرار گرفته است  و  جهت مقابله با حملات  \\nسایبری از یک سیستم تشخیص نفوذ (IDS) استفاده کرده است.  ما از  log  های اینIDS  استفاده خواهیم\\nو نقاط ضعف سازمان را پیدا می کنیم.   این نقاط ضعف را به سازمان اعلام می کنیم تا سازمان در زمینه برطرف  \\nنمودن این نقاط ضعف تصمیمات مقتضی را بگیرد.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 6, 'page_label': '7'}, page_content='3- گام دوم: درک داده ها یاData Understanding \\nدیتاست NSL-KDD در سال 2009  بعنوان نسخه جدید تجدید نظر شده در مجموعه داده اصلی  \\nKDDCup99  ارائه شد. از یک طرف ،NSL-KDD   ویژگی های سودمند و چالش برانگیز KDDCup \\nرا حفظ کرد. \\nاز طرف دیگر، با حذف رکوردهای اضافی، عقلانی کردن تعداد نمونه ها و حفظ تنوع نمونه های انتخاب شده،  \\nبه اشکالاتی که از مجموعه داده اصلی به ارث رسیده است پرداخته است. شایان ذکر است که مجموعه داده \\nNSL-KDD   برای به حداکثر رساندن سختی پیش بینی، که ویژگی های برجسته آن را تشکیل می دهد،\\nگردآوری شده است.  \\nدر کل  42  ویژگی برای دیتاست در نظر گرفته شده که41  ویژگی مربوط به داده های جمع آوری شده و\\nویژگی آخر نیز به عنوان برچسب هدف با عنوان نرمال یا حمله می باشد . \\nدر این تحقیق از مجموعه های KDDTrain+ ،KDDTest+   و KDDTrain+_20Percent  مجموعه\\nداده های  NSL-KDD   استفاده شده است مجموعه داده  NSL-KDD  شامل  مجموعه های  \\nKDDTrain+ ،KDDTest+  و KDDTrain+_20Percent  می باشدمجموعه داده های مجموعه \\nKDDTrain+   به عنوان مجموعه داده برای آموزش شامل125973  نمونه است که شامل58630  مورد'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 6, 'page_label': '7'}, page_content='داده های  NSL-KDD   استفاده شده است مجموعه داده  NSL-KDD  شامل  مجموعه های  \\nKDDTrain+ ،KDDTest+  و KDDTrain+_20Percent  می باشدمجموعه داده های مجموعه \\nKDDTrain+   به عنوان مجموعه داده برای آموزش شامل125973  نمونه است که شامل58630  مورد\\nترافیک حمله و  67343  نمونه ترافیک عادی است.  مجموعه KDDTest+   شامل22544  نمونه است و برای\\nتست از آن استفاده می شود.  KDDTrain+_20Percent  شامل20  درصد ازKDDTrain+  (11850  \\nنمونه)  می باشد و برای ارزیابی از آن استفاده می شود.  \\nهمانطور که قبلاً هم گفته شده در این دیتاست 42 ستون وجود دارد که41 ستون یا ویژگی مربوط به شبکه\\nهست و ستون  42  نیز برای برچسب گذاری نوع حمله و نرمال بودن است. (البته یک ستون43  نیز وجود دارد\\nکه از آن استفاده نمی شود). جدول زیر  مشخصات  41  ویژگی یا ستون  مربوطه  را  نمایش می  دهد .  \\n \\n \\n \\nDescription Type Feature name'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 7, 'page_label': '8'}, page_content='length (number of seconds) of the \\nconnection \\ncontinuous Duration 1 \\ntype of the protocol, e.g., tcp, udp, \\netc \\ndiscrete protocol_type 2 \\nNetwork service on the destination, \\ne.g., http, telnet, etc. \\ndiscrete Service 3 \\nnumber of data bytes from source to \\ndestination \\ncontinuous src_bytes 4 \\nnumber of data bytes from \\ndestination to source \\ncontinuous dst_bytes 5 \\nnormal or error status of the \\nconnection \\ndiscrete Flag 6 \\n1 if connection is from/to the same \\nhost/port; 0 otherwise \\ndiscrete Land 7 \\nnumber of ‘‘wrong’’ fragments continuous wrong_fragment 8 \\nnumber of urgent packets continuous Urgent 9 \\nnumber of ‘‘hot’’ indicators continuous Hot 10 \\nnumber of failed login attempts continuous num_failed_logins 11 \\n1 if successfully logged in; 0 \\notherwise \\ndiscrete logged_in 12 \\nnumber of ‘‘compromised’’ \\nconditions \\ncontinuous num_compromised 13 \\n1 if root shell is obtained; 0 \\notherwise \\ndiscrete root_shell 14 \\n1 if ‘‘su root’’ command attempted; \\n0 otherwise \\ndiscrete su_attempted 15'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 7, 'page_label': '8'}, page_content='otherwise \\ndiscrete logged_in 12 \\nnumber of ‘‘compromised’’ \\nconditions \\ncontinuous num_compromised 13 \\n1 if root shell is obtained; 0 \\notherwise \\ndiscrete root_shell 14 \\n1 if ‘‘su root’’ command attempted; \\n0 otherwise \\ndiscrete su_attempted 15 \\nnumber of ‘‘root’’ accesses continuous Num_root 16 \\nnumber of file creation operations continuous Num_file_c \\nreations \\n17 \\nnumber of shell prompts continuous Num_shells 18 \\nnumber of operations on access \\ncontrol files \\ncontinuous Num_acces \\ns_files \\n19 \\nnumber of outbound commands in \\nan ftp session \\ncontinuous num_outbound_cm\\nds \\n20 \\n1 if the login belongs to the ‘‘hot’’ \\nlist; 0 otherwise \\ndiscrete is_hot_login 21 \\n1 if the login is a ‘‘guest’’login; 0 \\notherwise \\ndiscrete is_guest_login 22'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 8, 'page_label': '9'}, page_content='number of connections to the same \\nhost as the \\ncurrent connection in the past two \\nseconds \\ncontinuous Count 23 \\n% of connections that have ‘‘SYN’’ \\nerrors \\ncontinuous serror_rate 24 \\n% of connections that have ‘‘REJ’’ \\nerrors \\ncontinuous rerror_rate 25 \\n% of connections to the same \\nservice \\ncontinuous same_srv_rate 26 \\n% of connections to different \\nservices \\ncontinuous diff_srv_rate 27 \\nnumber of connections to the same \\nservice as the current connection in \\nthe past two seconds \\ncontinuous srv_count 28 \\n% of connections that have ‘‘SYN’’ \\nerrors \\ncontinuous srv_serror_rate 29 \\n% of connections that have ‘‘REJ’’ \\nerrors \\ncontinuous srv_rerror_rate 30 \\n% of connections to different hosts continuous srv_diff_host_rate 31 \\ncount for destination host continuous dst_host_count 32 \\nsrv_count for destination host continuous dst_host_srv_count 33 \\nsame_srv_rate for destination host continuous dst_host_same_srv_\\nrate \\n34 \\ndiff_srv_rate for destination host continuous dst_host_diff_srv_r\\nate \\n35'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 8, 'page_label': '9'}, page_content='srv_count for destination host continuous dst_host_srv_count 33 \\nsame_srv_rate for destination host continuous dst_host_same_srv_\\nrate \\n34 \\ndiff_srv_rate for destination host continuous dst_host_diff_srv_r\\nate \\n35 \\nsame_src_port_rate for destination \\nhost \\ncontinuous dst_host_same_src_\\nport_rate \\n36 \\ndiff_host_rate for destination host continuous dst_host_diff_host_\\nrate \\n37 \\nserror_rate for destination host continuous dst_host_serror_rate 38 \\nsrv_serror_rate for destination host continuous dst_host_srv_serror\\n_rate \\n39 \\nrerror_rate for destination host continuous dst_host_rerror_rate 40 \\nsrv_serror_rate for destination hos continuous dst_host_srv_rerror\\n_rate \\n41'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 10, 'page_label': '11'}, page_content='4- گام سوم: آماده سازی داده ها یاData Preparation \\nچونمجموعه  داده ها شامل  نام ستون ها  نمی شود، ابتدا باید نام ستون ها  را اضافه  کنی م. \\nتغییر بعدی   که   می   خواهیم  انجام  دهی م  در  مورد   attack field  است.  ما  ستونی   را با عنوان  attack_flag  \\nاضافه می  کنی م  که  مقادیر  \"عادی\" را  به  عنوان  0 و مقدار   حمله را به عنوان  1 رمزگذاری م ی کند . \\nدر  مرحله   بعد،  ما   یک فیلد جدید به نام  attack_map  اضافه می کنیم  و  هر  یک   از  حملات  را  بر   اساس   نوع   \\nحمله  (   فیلد  attack   )  و بر اساس جدول زیر به5  دسته4  دسته حمله و یک دسته ترافیک نرمال  طبقه بند ی \\nمی کنیم. \\nattack  attack_map \\nnormal Normal 0 \\n▪ apache2 \\n▪ back \\n▪ land \\n▪ neptune \\n▪ mailbomb \\n▪ pod \\n▪ processtable \\n▪ smurf \\n▪ teardrop \\n▪ udpstorm \\n▪ worm \\nDenial of Service attacks 1 \\n▪ ipsweep \\n▪ mscan \\n▪ nmap \\n▪ portsweep \\n▪ saint \\n▪ satan \\nProbe attacks 2 \\n▪ buffer_overflow \\n▪ loadmdoule \\n▪ perl \\n▪ ps \\n▪ rootkit \\n▪ sqlattack \\n▪ xterm \\nPrivilege escalation attacks 3'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 11, 'page_label': '12'}, page_content='▪ ftp_write \\n▪ guess_passwd \\n▪ http_tunnel \\n▪ imap \\n▪ multihop \\n▪ named \\n▪ phf \\n▪ sendmail \\n▪ snmpgetattack \\n▪ snmpguess \\n▪ spy \\n▪ warezclient \\n▪ warezmaster \\n▪ xclock \\n▪ xsnoop \\nRemote access attacks 4 \\n \\nبرخی  حدسیات  اولی ه   از   آنچه  در   مجموعه  داده  داریم   می تواند مفید باشد .  در اینجا ما  ی ک  جدول  ساده  از   \\nattack  و  پروتکلی که برای این حمله از آن استفاده شده  است  داریم.  در   تجزیه   و   تحلیل   ترافی ک  شبکه   ،پروتکل   \\nیک  ابزار   ساده   برا ی   ایجاد   چند   دسته  اولی ه   برای   دسته   بند ی  داده   هاست.  در   این   بخش ما ترافیک عادی  \\n(normal)  رابه عنوان  یک  معیار در  مجموعه درنظر گرفته ایم.  \\nprotocol_type  attack icmp tcp udp \\nback 0 956 0 \\nbuffer_overflow 0 30 0 \\nftp_write 0 8 0 \\nguess_passwd 0 53 0 \\nimap 0 11 0 \\nipsweep 3117 482 0 \\nland 0 18 0 \\nloadmodule 0 9 0 \\nmultihop 0 7 0 \\nneptune 0 41214 0 \\nnmap 981 265 247 \\nnormal 1309 53599 12434 \\nperl 0 3 0 \\nphf 0 4 0'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 12, 'page_label': '13'}, page_content='pod 201 0 0 \\nportsweep 5 2926 0 \\nrootkit 0 7 3 \\nsatan 32 2184 1417 \\nsmurf 2646 0 0 \\nspy 0 2 0 \\nteardrop 0 0 892 \\nwarezclient 0 890 0 \\nwarezmaster 0 20 0 \\n \\nما از جدول بالا می توانیم بفهمیم که بیشترحملات  ی ک   پروتکل  خاص   را  هدف   قرار  می  دهند . اما چندین  \\nپروتکل (مثلا satan, nmap, ipsweep ) وجود دارند که از هر سه پروتکل استفاده می کنند \\nهمچنین از اینکه  داده   های  icmp  در  ترافی ک  معمول ی  کمتر  یافت  می  شود   می توان حدس زد که از این  \\nپروتکل جهت حمله استفاده شده است. \\nنمودار زیر با استفاده از داده های جدول بالا رسم شده است'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 13, 'page_label': '14'}, page_content='نکته قابل  توجه  در اینجا تفاوت در  هر نوع  پروتکل  است. می بینیم که هر نوع پروتکل بیشتر جهت یک یا  \\nچند نوع از حملات به خصوصی استفاده شده است.  \\nما در اینجا می توانیم حدس بزنیم که  پروتکل  ممکن است  برای شناسایی نوع  ترافیکی   که  مشاهده می  کن یم  \\nمفید  باشد .  \\nحالا می خواهیم ببینیم که آیا Flag  هم می تواند جهت شناسایی نوع ترافیک به ما کمک کند. برای این\\nمنظور ما ترافیک های عادی و حمله شبکه را بر اساس فیلد Flag  دسته بندی می کنیم و نمودار زیر را به\\nدست می آوریم :  \\n \\n \\n \\n \\nدر اینجا مشاهده می کنیم که بیشتر ترافیک های عادی شبکه Flag آن ها برابرSF  می باشد و بیشتر\\nترافیک های حمله هم Flag آن ها برابرS0 است. در نتیجهFlag  هم می تواند جهت شناسایی نوع\\nترافیک مفید باشد. \\nدر مرحله بعد همین کار روی Service نیز انجام می دهیم کهنمودار زیر دسته بندی  ترافیک های عادی و  \\nحمله شبکه را بر اساس فیلد  Flag نمایش می دهد'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 14, 'page_label': '15'}, page_content='در اینجا نیز می بینیم که در ترافیک حمله بیشترینFlag  برابرPrivate  و در ترافیک عادی بیشترین ترافیک\\nبرابر  http می باشد.(که قابل انتظار نیز می باشد چرا که بیشتر کاربران عادی جهت دسترسی به صفحات وب\\nاز اینترنت استفاده می کنند.) \\nو نکته مهم تر این است که  در  حالی  که  حجم  عظیمی  از  ترافیک  عادی  http  است،  چند   سرویس  در  مجموعه   \\nحمله  وجود   دارد  یعنی  ترافی ک  حمله   ما   در   همه  جا   است.  به   این   معنی   است   که  حملات  بسیاری   مسیرهای   \\nمختلف  را در  س یستم ها  جستجو م ی کنند .'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 15, 'page_label': '16'}, page_content='اگر  از  چشم   یک   مد یر  شبکه   به  این  موضوع  فکر   کنیم،   ترک یب  پروتکل،   پرچم  و  سروی س  به   نظر   می   رسد   که   \\nباید  چیزهای زیادی  در  مورد   ماهیت ترافی ک  ما به  ما بگوید . جفت  کردن  آنها با  مدت  زمان اتصال  و  مقدار  داده   \\nدر آن اتصال نقطه  شروع خوب ی برای  ما به نظر  می رسد .  \\nبه نظر می رسد که ویژگی هایی که در مرحله قبل به دست آوردیم یعنی  protocol_type،  سرویس   و   پرچم   \\nمی تواند مفید باشد.  تنوع   کافی  بین   اینها  وجود  دارد   که  ما  باید   بتوانیم   سطح  پایه   ای   از  شناسایی  را  بدست   \\nآوریم.   ما  همچن ین  قصد   دار یم  برخی   از   داده  ها ی  عدد ی  اولیه   را   وارد  کنیم:  مدت   زمان،   src_bytes،  \\ndst_bytes .  این ویژگی ها احتماباید   چیزهای  زیادی  در  مورد  آنچه  در  شبکه  ما  اتفاق  می  افتد   به   ما  بگویند .  \\nقبل از اینکه وارد مرحله مدل سازی باید داده های خود کد گذاری کنیم. ما از روش کد گذاری  one-hot \\nencoding استفاده می کنیم روش ی است  که  به  ما امکان م ی دهد  یک  کدگذاری  سری ع روی  ستون های خود'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 15, 'page_label': '16'}, page_content='قبل از اینکه وارد مرحله مدل سازی باید داده های خود کد گذاری کنیم. ما از روش کد گذاری  one-hot \\nencoding استفاده می کنیم روش ی است  که  به  ما امکان م ی دهد  یک  کدگذاری  سری ع روی  ستون های خود   \\nانجام  دهیم.  این روش   هر   مقداری  را  که  در   یک  ستون  پی دا  میکند   را  م ی گیرد  و   برای   هر  مقدار  ی ک  ستون   \\nجداگانه با 0 یا 1 ایجاد  می کند، که  نشان م ی دهد  آیا آن  ستون \" فعال\" است یا  خیر.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 16, 'page_label': '17'}, page_content='گام چهارم: مدل سازی یاModeling \\nحال که اهداف طبقه  بند ی   خود را  تعیین  کردیم می توانیم کار مدل سازی را شروع کنیم. \\nدر این مرحله ما  از ویژگی هایی که در مرحله قبل به دست آوردیم استفاده می کنیم و داده ها را طبقه بندی  \\nمی کنیم.  \\nما  روی   مجموعه   آموزش ی   خود دو مدل را آموزش می دهیم و تست می کنیم  :  طبقه   بند ی  دودویی   و  چندگانه  \\nما برای طبقه بندی  از الگوریتم طبقه بندی  جنگل تصادفی  (random forest) وk  نزدیک ترین همسایه\\n(K-nearest neighbors )استفاده می کنیم \\n1. الگوریتمجنگل تصادفی   (  Random Forest  ) : \\nجنگل تصادفی یا  Random Forest نوعی الگوریتم یادگیری گروهی  Ensemble Learning \\nAlgorithm)   است که چندین درخت تصمیم را برای پیشبینی ترکیب می کند. هر درخت تصمیم در جنگل  \\nتصادفی بر روی یک زیر مجموعه تصادفی از داده های آموزشی و یک زیر مجموعه تصادفی از فیچرها آموزش  \\nداده می شود. سپس خروجی جنگل تصادفی با تجمیع پیشبینیهای همه درخت های تصمیم تعیین می شود.  \\nاین رویکرد به جنگل تصادفی اجازه می دهد تا بسیار دقیق و مقاوم در برابر مشکل بیشبرازش، یک مشکل'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 16, 'page_label': '17'}, page_content='داده می شود. سپس خروجی جنگل تصادفی با تجمیع پیشبینیهای همه درخت های تصمیم تعیین می شود.  \\nاین رویکرد به جنگل تصادفی اجازه می دهد تا بسیار دقیق و مقاوم در برابر مشکل بیشبرازش، یک مشکل  \\nرایج در یادگیری ماشین که در آن مدل در داده های آموزشی خوب عمل می کند اما در داده های جدید ضعیف  \\nاست، باشد . \\nمراحل الگوریتم جنگل تصادفی \\n1. آماده سازی دادهها  : اولین مرحله آماده سازی داده ها برای آموزش مدل است که شامل پاکسازی  \\nداده ها، حذف مقادیر از دست رفته و تبدیل متغیرهای طبقه بندی شده Categorical) به متغیرهای\\nعددی است. سپس داده ها به مجموعه های آموزشی و آزمایشی تقسیم می شوند . \\n2. انتخاب تصادفی زیر مجموعه  : مرحله بعدی انتخاب تصادفی زیرمجموعه ای از فیچرها برای هر درخت  \\nدر جنگل است. این کار برای کاهش بیش برازش و افزایش تنوع درختان انجام می شود. \\n3. ساخت درخت  : مرحله بعدی ساخت درختهای تصمیم با استفاده از زیرمجموعه ای از فیچرهاست که  \\nبه طور تصادفی انتخاب شده اند. درختهای تصمیم با استفاده از یک الگوریتم تقسیم باینری بازگشتی'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 17, 'page_label': '18'}, page_content='ساخته میشوند، که در آن هر گره داخلی داده ها را بر اساس یک فیچر و مقدار آستانه انتخاب شده  \\nبه دو زیر مجموعه تقسیم می کند . \\n4. رای گیری  : هنگامی که تمام درخت های تصمیم ساخته شدند، مرحله بعدی پیش بینی مجموعه  \\nتست است. این کار با جمع آوری پیش بینی ها از تمام درختان جنگل با استفاده از مکانیزم رای گیری  \\nانجام می شود. در تسک های طبقه بندی، کلاسس که توسط اکثریت درختان به عنوان پیش بینی  \\nنهایی، پیشبینی شده انتخاب می شود. در تسک های رگرسیون، میانگین پیش بینی درختان به عنوان  \\nپیش بینی نهایی انتخاب می شود. \\n5. ارزیابی مدل  : در نهایت، عملکرد مدل با استفاده از معیارهای مختلفی مانند Accuracy،precision \\n،recall   و  F1 score ارزیابی میشود. اگر عملکرد مدل رضایت بخش باشد، می توان از آن برای  \\nپیش بینی داده های جدید استفاده کرد. این مراحل به صورت مکرر، با زیرمجموعه های مختلف فیچرها  \\nو زیرمجموعه های مختلف داده، تکرار می شوند تا به سطح مورد نظر از دقت دست پیدا کنند  .\\nRandom Forest   یک الگوریتم یادگیری ماشین قدرتمند است که میتواند وظایف پیچیده را  \\nانجام دهد و پیش بینی های بسیار دقیقی را با حداقل بیشبرازش ایجاد کند'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 17, 'page_label': '18'}, page_content='و زیرمجموعه های مختلف داده، تکرار می شوند تا به سطح مورد نظر از دقت دست پیدا کنند  .\\nRandom Forest   یک الگوریتم یادگیری ماشین قدرتمند است که میتواند وظایف پیچیده را  \\nانجام دهد و پیش بینی های بسیار دقیقی را با حداقل بیشبرازش ایجاد کند  \\nابتدا ما از الگوریتم  random forest  استفاده کنیمو با این الگوریتم مدل سازی می کنیم و سپس با استفاده  \\nاز داده های آموزشی مدل خود را آموزش می دهیم  و  با استفاده از داده های اعتبار سنجی تست می کنیم و   \\nبه دقت  0.9925116426756986 دست پیدا می کنیم. \\n \\nهمانطور که مشاهده می کنیم الگوریتم random forest به دقت قابل قبولی دست پیدا کردهاست.  \\nاکنون  می توانیم  نتایج  خود   را   دقیق تر  بررس ی   کنی م  تا ببینیم آیا می توانیم به دقت بهتری نیز دست پیدا کنیم  \\nیا خیر؟'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 18, 'page_label': '19'}, page_content='اولین  کار ی  که  م ی توانیم  انجام  دهیم  این  است  که  ی ک  ماتریس  سردرگمی   را رسم کنیم،  که  در  این  مورد   \\nطبقه بند ی پیش بینیشده را  در کنار طبقه بند ی واقعی  ترسیم می کند تا آن ها را با هم مقایسه کنیم:  \\n \\nکه به نظر می رسد برخی از حملات را به درستی پیش بینی نکرده است و همچنین برخی از مقادیری را که  \\nبه عنوان حمله پیش بینی کرده است در واقع حمله نبوده اند. \\nبه عبارتی دیگر  ما  در  اینجا خطای  مثبت  کاذب  زیادی   (تراف یک  معمولی   که  به   عنوان   یک   حمله   شناسایی  شده  \\nاست) و منفی  های  کاذب  (ترافیک حمله  که به  صورت عاد ی شناسایی شده است) را  م ی بینیم.  \\nبنابراین  کمی  خطاهای  پیش بینی  را  بررس ی   کنی م  تا  بب ینی م  آیا  اطلاعات  بیشتری   برای استخراج  وجود دارد  یا   \\nخیر؟ تا با کمک آن ها دقت مدل سازی خود را تقویت کنیم. \\nدر این مرحله ما برای این که بفهمیم کدام یک از ویژگی ها در مدل سازی اهمیت داشته است و ما آن ویژگی  \\nها را در نظر نگرفته ایم می توانیم از نرخ  مثبت   کاذب   (false positive  )و  منفی   کاذب  (false negative  )'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 18, 'page_label': '19'}, page_content='در این مرحله ما برای این که بفهمیم کدام یک از ویژگی ها در مدل سازی اهمیت داشته است و ما آن ویژگی  \\nها را در نظر نگرفته ایم می توانیم از نرخ  مثبت   کاذب   (false positive  )و  منفی   کاذب  (false negative  )\\nویژگی ها استفاده کنیم که درشکل های زیر به ترتیب مقدار انحراف معیار (std  )مثبت کاذب  و منفی  کاذب   \\nهریک از معیار ها را مشاهده می کنیم:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 20, 'page_label': '21'}, page_content='همانطور که مشاهده می کنیم  اکثر معیار ها در نرخ مثبت کاذب انحراف معیار کمی دارند اما  در  منفی  ها ی  \\nکاذب،  همه  سطرها  درجاتی  از  واریانس  دارند .  این  به  ما  نشان  می  دهد   که  ممکن  است  اطلاعات  خوبی  در  آن   \\nسطر ها وجود  داشته  باشد  زیرا بین مشاهدات یک طبقه بند ی در  مقابل طبقه دیگر  تفاوت وجود دارد.  \\nپس به  موارد  منفی  کاذب  توجه می کنیم  تا ببینی م چه نوع حملات ی را  از  دست داده  ایم.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 21, 'page_label': '22'}, page_content='شکل زیرنوع حملات با بیشترین مقدار منفی  کاذب را نشان می دهد.  \\n \\nNeptune  وSatan بیشترین نوع حملات از دست رفته اند (حملاتی که شناسایی نشده اند.) \\nدر این مرحله ما تلاش می کنیم که بتوانیم این نوع حملات را نیز به درستی طبقه بندی کنیم یا به عبارتی  \\nنرخ منفی کاذب آن ها را پایین بیاوریم.  \\nبه این منظور ما ویژگی هایی که بیشترین نرخ منفی کاذب را  دارند را  دست می آوریم  که در  شکل  زیر به  \\nترتیب آورده شده اند:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 22, 'page_label': '23'}, page_content='ما ویژگی های فوق را نیز به مجمعه ویژگی های خود جهت طبقه بندی اضافه می کنیم و مجددا مدل را آوزش\\nمی دهیم. این بار روی داده های اعتبارسنجی ما به دقتی برابر  0.9937446416664021  دست پیدا می\\nکنیم  که می بینیم دقت ما نسبت به مرحله قبل بهبود پیدا کرده است. \\n \\nمجددا جهت مشاهده پیش بینی های از دست رفته ماتریس سردرگمی (confustion matrix) را رسم می  \\nکنیم.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 23, 'page_label': '24'}, page_content='همانطور که می بینیم نرخ مثبت و منفی کاذب کمتری را شاهد هستیم و این به معنای بهبود عملکرد الگوریتم\\nطبقه بندی ما می باشد. \\nمجددا نوع حملات با بیشترین مقدار منفی کاذب را رسم می کنیم.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 24, 'page_label': '25'}, page_content='به نظر می رسد که عملکرد الگوریتم مدل سازی ما بهتر شده و ما از هرکدام از انواع حملات فقط چند مورد\\nخاص را به درستی شناسایی نکرده ایم. البته حمله   Neptune  همچنان نرخ منفی کاذب زیادی دارد، که به\\nنظر می رسد شناسایی این نوع حمله برای الگوریتم سخت می باشد. \\nدر  مرحله بعد ،   توجه   خود   را   به  سناریو ی  چند   طبقه   بند ی   معطوف   می کنیم.  در  اینجا  م ی  خواهیم   ببین یم   که   \\nآیا می  توانیم  نوع حمله  را  از  روی  داده ها شناسایی  کنیم.  به یاد  داشته  باش ید، ما چهار نوع حمله  داریم:  \\nDOS \\nProbe \\nPrivilege escalation \\nRemote access'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 25, 'page_label': '26'}, page_content='ما مدل پایه خود را بر اساس الگوریتم جنگل تصادفی می سازیم و با استفاده از داده های آموزشی مدل خود\\nرا آموزش می دهیم و با استفاده از داده های اعتبار سنجی تست می کنیم و به دقت  \\n0.976489733276884  دست پیدا می کنیم \\n \\nسپس ویژگی   های  جدیدی که در مرحله قبل به دست آوردیم را به مدل اضافه می کنیم و به دقت  \\n0.9773600482646937  دست پیدا می کنیم و همانطور که مشاهده می کنیم دقت ما بهبود پیدا کرده\\nاست.  \\n \\nجهت بررسی بیشتر مدل خود،  ما ماتریس سردرگمی را برای طبقه بندی چند کلاسه (طبقه بندی انواع حمله)   \\nرسم خواهیم کرد. این ماتریس نوع حمله پیش بینی شده را بر اساس نوع حمله واقعی ترسیم می کند.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 26, 'page_label': '27'}, page_content='شکل زیر بیشترین نوع حملاتی را که به درستی طبقه بندی نشده اند را  برای دسته بندی چند کلاسه   نشان  \\nمی دهد.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 27, 'page_label': '28'}, page_content='2- الگوریتم  K-nearest neighbors   : \\nالگوریتم K نزدیکترین همسایه K-Nearest Neighbors ) یکی از این الگوریتم های توانمند است\\nالگوریتم K نزدیکترین همسایه KNN) یک الگوریتم یادگیری ماشین نظارت شده است و از ویژگی های آن\\nسادگی و آسانی این الگوریتم برای پیاده سازی است که می تواند برای حل مسائل طبقه بندی و رگرسیون مورد  \\nاستفاده قرار گیرد. الگوریتم نزدیک ترین همسایگی کاربرد فراوانی در داده کاوی دارد و یک الگوریتم بسیار  \\nمحبوب در این زمینه است. \\nالگوریتم K نزدیک ترین همسایه یا KNN   یکی از سادهترین الگوریتم های یادگیری ماشین باناظر است که  \\nبرای حل مسائل طبقه بندی و رگرسیون استفاده می شود. \\nاین الگوریتم برای مسائل طبقه بندی k نزدیک ترین همسایه را پیدا و با اکثریت آرا نزدیکترین همسایگان  \\nکلاس را پیشبینی می کند .'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 28, 'page_label': '29'}, page_content='برای مسائل رگرسیون k نزدیکترین همسایه را پیدا و با محاسبه ی میانگین مقدار نزدیک ترین همسایهها، \\nمقدار مدنظر را پیشبینی می کند . \\nمراحل الگوریتم K نزدیکترین همسایه  \\n1. دادهها را بارگذاری می کنیم. \\n2. مقدار K را تعیین میکنیم که همان تعداد نزدیک ترین همسایهها هستند . \\n3. برای هر نمونه داده: \\n• فاصلهی میان نمونه داده ی جدید را با نمونه داده های موجود محاسبه می کنیم. \\n• فاصله و شاخص هر نمونه را به یک فهرست وارد می کنیم. \\n4. کل لیست را براساس فاصلهی نمونه داده ها، از کمترین به بیشترین فاصله، مرتب می کنیم. \\n5. K  تا از اولین نمونههای فهرست مرتب شده را به عنوان K نزدیکترین همسایه انتخاب می کنیم. \\n6. برچسب این K نمونه را بررسی میکنیم. \\n7. اگر مسئله رگرسیون باشد، میانگین برچسبهای این K نمونه داده برچسب نمونه داده جدیدمان خواهد\\nبود. \\n8. درصورتیکه مسئله طبقه بندی باشد، نمونه ی جدید هم همان برچسب K همسایه را خواهد داشت. \\nدر این مرحله  ما از الگوریتم  KNN  استفاده کنیم و با این الگوریتم مدل سازی می کنیم و سپس با استفاده\\nاز داده های آموزشی مدل خود را آموزش می دهیم و با استفاده از داده های اعتبار سنجی تست می کنیم.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 28, 'page_label': '29'}, page_content='در این مرحله  ما از الگوریتم  KNN  استفاده کنیم و با این الگوریتم مدل سازی می کنیم و سپس با استفاده\\nاز داده های آموزشی مدل خود را آموزش می دهیم و با استفاده از داده های اعتبار سنجی تست می کنیم.  \\nدر مرحله اول ما الگوریتم  KNN  را با پارامترهای پیش فرض خود الگوریتم اجرا می کنیم و به دقتی معادل\\n0.9912283022861982 دست پیدا می کنیم'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 29, 'page_label': '30'}, page_content='ما سپس تلاش می کنیم که با تغییر پارامترها و یا ویژگی های دقت الگوریتم را بهبود ببخشیم \\nمشابه کاری که در الگوریتم  random forest  انجام دادیم ابتدا  ماتریس   سردرگم ی  را رسم کنیم،  که   مورد   \\nطبقه بند ی پیش بینیشده را  در کنار طبقه   بند ی واقعی  ترسیم می کند تا آن ها را با هم مقایسه کنیم:  \\n \\n \\nکه به نظر می رسد برخی از حملات را به درستی پیش بینی نکرده است و همچنین برخی از مقادیری را که  \\nبه عنوان حمله پیش بینی کرده است در واقع حمله نبوده اند.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 30, 'page_label': '31'}, page_content='به عبارتی دیگرما  در  آنجا  نکات  مثبت  کاذب  زیادی  (ترافی ک  معمولی   که  به  عنوان  یک   حمله  شناسایی  شده   \\nاست) و منفی  های  کاذب  (ترافیک حمله  که به  صورت عاد ی شناسایی شده است) را  م ی بینیم.  \\nبنابراین  کمی  خطاهای  پیش بینی  را  بررس ی   کنی م  تا  بب ینی م  آیا  اطلاعات  بیشتری   برای استخراج  وجود دارد  یا   \\nخیر؟ تا با کمک آن ها دقت مدل سازی خود را تقویت کنیم. \\nدر این مرحله ما برای این که بفهمیم کدام یک از ویژگی ها در مدل سازی اهمیت داشته است و ما آن ویژگی  \\nها را در نظر نگرفته ایم می توانیم از نرخ  مثبت   کاذب   (false positive  )و  منفی   کاذب  (false negative  )\\nویژگی ها استفاده کنیم که درشکل های زیر به ترتیب مقدار انحراف معیار (std  )مثبت کاذب  و منفی  کاذب   \\nهریک از معیار ها را مشاهده می کنیم:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 32, 'page_label': '33'}, page_content='همانطور که مشاهده می کنیم اکثر معیار ها در نرخ مثبت کاذب انحراف معیار کمی دارند امادر  منفی  ها ی  \\nکاذب،  همه  ستون   ها  درجاتی   از  واریانس   دارند .  این   به   ما  نشان  می  دهد   که  ممکن  است  اطلاعات  خوبی  در  آن   \\nستون ها وجود  داشته  باشد  زیرا بین مشاهدات یک  طبقه بند ی در  مقابل طبقه دیگر  تفاوت وجود  دارد.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 33, 'page_label': '34'}, page_content='پسبه  موارد  منفی  کاذب  توجه می کنیم  تا ببینی م چه نوع حملات ی را  از  دست داده  ایم. \\nشکل زیر نوع حملات با بیشترین مقدار منفی کاذب را نشان می دهد.  \\n \\nNeptune  وSatan بیشترین نوع حملات از دست رفته اند. (حملاتی که شناسایی نشده اند \\nدر این مرحله ما تلاش می کنیم که بتوانیم این نوع حملات را نیز به درستی طبقه بندی کنیم یا به عبارتی  \\nنرخ منفی کاذب آن ها را پایین بیاوریم.  \\nبه این منظور ما ویژگی هایی که بیشترین نرخ منفی کاذب را دست می آوریم که در جدول زیر به ترتیب  \\nآورده شده اند:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 34, 'page_label': '35'}, page_content='ما ویژگی های فوق را نیز به مجمعه ویژگی های خود جهت طبقه بندی اضافه می کنیم و مجددا مدل را\\nآموزش می دهیم. این بار روی داده های اعتبارسنجی ما به دقتی برابر  0.99276029593878  دست پیدا\\nمی کنیم که می بینیم دقت ما نسبت به مرحله قبل بهبود پیدا کرده است.  \\n \\nمجددا جهت مشاهده پیش بینی های از دست رفته ماتریس سردرگمی (confustion matrix) را رسم می   \\nکنیم.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 35, 'page_label': '36'}, page_content='همانطور که می بینیم نرخ مثبت و منفی کاذب کمتری را شاهد هستیم و این به معنای بهبود عملکرد الگوریتم\\nطبقه بندی ما می باشد. \\nمجددا نوع حملات با بیشترین مقدار منفی کاذب را رسم می کنیم.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 36, 'page_label': '37'}, page_content=\"در مرحله بعد ما جهت بهبود عملکرد الگوریتم طبقه بندی خود، سعی می کنیم برخی پارامترهای الگوریتم\\nKNN را تغییر دهیم \\nهمانطور که می دانیم مقادیر پیش فرض الگوریم KNN به شرح زیر است \\nWeights = ’uniform’ \\nAlgorithm = ’auto’ \\nMetric = ’minkowski’ \\nدر مرحله اول ویژگیmetric='manhattan'  قرار می دهیم وبه دقتی   0.9928555552027435  برابر  \\nدست پیدا می کنیم که بهتر می باشد.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 37, 'page_label': '38'}, page_content=\"در مرحله دوم ویژگی  weights='distance'  قرار می دهیم وبه دقتی  0.9931413329946337  برابر  \\nدست پیدا می کنیم که بهتر می باشد.  \\n \\nدر مرحله سوم ویژگی algorithm='brute' قرار می دهیمکه  دقت مدل تفاوت چندانی نمی کند .  \\n \\nدر مرحله آخر،  ویژگی های  metric  وweights  را تنظیم می کنیم و با آن ها مدل را آموزش می دهیم و\\nارزیابی می کنیم و به دقت  0.9932048391706093  که دقت قابل قبولی می باشد\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 38, 'page_label': '39'}, page_content='شکل زیر ماتریس سردرگمی نهایی را برای دسته بندی دودویی نمایش می دهد \\n \\nشکل زیر نیز نوع حملات با بیشترین مقدار منفی کاذب را نشان می دهد  \\nهمان طور که می بینیم کاهش داشته است.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 39, 'page_label': '40'}, page_content='به نظر می رسد که عملکرد الگوریتم مدل سازی ما بهتر شده و ما از هرکدام از انواع حملات فقط چند مورد\\nخاص را به درستی شناسایی نکرده ایم. البته حمله   Neptune  همچنان نرخ منفی کاذب زیادی دارد، که به\\nنظر می رسد شناسایی این نوع حمله برای الگوریتم سخت می باشد. \\nدر  مرحله بعد ،   توجه   خود   را   به  سناریو ی  چند   طبقه   بند ی   معطوف   می کنیم.  در  اینجا  م ی  خواهیم   ببین یم   که   \\nآیا می  توانیم  نوع حمله  را  از  روی  داده ها شناسایی  کنیم.  به یاد  داشته  باش ید، ما چهار نوع حمله  داریم:  \\nDOS \\nProbe \\nPrivilege escalation \\nRemote access'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 40, 'page_label': '41'}, page_content='ما مدل پایه خود را بر اساس الگوریتمKNN  می سازیم و با استفاده از داده های آموزشی مدل خود را آموزش\\nمی دهیم و با استفاده از داده های اعتبار سنجی تست می کنیم و به دقت  0.9756429932260796  دست\\nپیدا می کنیم.  \\n \\nسپس ویژگی های جدیدی که در مرحله قبل به دست آوردیم را به مدل اضافه می کنیم و به دقت  \\n0.9758994062172547  دست پیدا می کنیم و همانطور که مشاهده می کنیم دقت ما بهبود پیدا کرده\\nاست.  \\n \\nدر این مرحله  الگوریتم  هم از تعداد پارامترهای مناسبی برخوردار است و هم پارامترهای الگوریتم به دقت  \\nتنظیم شده است. \\nبنابراین در این مرحله امکان  بهبود جدیدی در الگوریتم وجود ندارد.  \\nشکل زیر ماتریس سردرگمی نهایی را برای دسته بندی چند کلاسه  نمایش می دهد:'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 41, 'page_label': '42'}, page_content='شکل زیر بیشترین نوع حملاتی را که به درستی طبقه بندی نشده اند را برای دسته بندی چند کلاسه نشان\\nمی دهد.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 43, 'page_label': '44'}, page_content='5- گام پنجم: ارزیابی یا Evaluating \\nحاکه ما با استفاده از دو الگوریتم طبقه بندی جنگل تصادفی (random forest) وk  نزدیک ترین همسایه\\n(KNN) مدل خود را ساختیم، نوبت به ارزیابی مدل می رسدمدل  خود  را  که با استفاده از داده های آموزشی  \\nآموزش داده ایم، در برابر برخ ی از داده های نادیده (داده های تست) ارزیابی می کنیم.  ما می توانیم این را به   \\nعنوان تراف یک شبکه  جد ید  در نظر  بگ یریم.  \\nارزیابی الگوریتم جنگل تصادفی :  \\nابتدا مدل طبقه بندی دودویی را تست می کنیم :  \\nهنگام تست الگوریتم با داده های تا الان ندیده است   (داده های تست) ما دقتی برابر با  \\n0.8035753892560884  می گیریم. همانطور که ملاحظه می کنید، دقت مدل ما بر روی داده های تست\\nافت داشته است. \\n \\nدر شکل  ماتریس سردرگمی  را برای طبقه بندی دودویی می بینیم :'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 44, 'page_label': '45'}, page_content='شکل زیر بیشترین نوع حملاتی را که به درستی طبقه بندی نشده اند را نشان می دهد'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 45, 'page_label': '46'}, page_content='سپس مدل طبقه بندی چند کلاسه را تست می کنیم \\nهنگام تست الگوریتم با داده های تست ما دقتی برابر با  0.7530053675198509 می گیریم \\n \\nهمانطور که می بینیم دقت طبقه بندی چند کلاسه به دلیل اینکه در طبقه بندی چند کلاسه احتمال خطا  \\nبیشتر وجود نسبت به دسته بندی دودویی کمتر می باشد.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 46, 'page_label': '47'}, page_content='در شکل ماتریس سردرگمی را برای طبقه بندیچند کلاسه می بینیم :  \\n \\nشکل زیر بیشترین نوع حملاتی را که به درستی طبقه بندی نشده اند را  برای دسته بندی چند کلاسه   نشان  \\nمی دهد.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 47, 'page_label': '48'}, page_content='ارزیابی الگوریتمKNN  : \\nابتدا مدل طبقه بندی دودویی را تست می کنیم \\nهنگام تست الگوریتم با داده های تا الان ندیده است   (داده های تست) ما دقتی برابر با  \\n0.8014904848511734  می گیریم. همانطور که ملاحظه می کنید، دقت مدل ما بر روی داده های تست\\nافت قابل ملاحظه ای داشته است.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 48, 'page_label': '49'}, page_content='ماتریس سردرگمی را برای الگوریتمKNN مشاهده می کنیم \\n \\n \\nشکل زیر بیشترین نوع حملاتی را که به درستی طبقه بندی نشده اند را نشان می دهد.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 49, 'page_label': '50'}, page_content='سپس مدل طبقه بندی چند کلاسه را تست می کنیم \\nهنگام تست الگوریتم با داده های تست ما دقتی برابر با  0.6738677194694583 می گیریم \\n \\nهمانطور که می بینیم دقت طبقه بندی چند کلاسه به دلیل اینکه در طبقه بندی چند کلاسه احتمال خطا  \\nبیشتر وجود نسبت به دسته بندی دودویی کمتر می باشد.  این احتمال وجود دارد که مدل ما دچار بیش'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 50, 'page_label': '51'}, page_content='برازشover fitting) شده باشد.یعنی اینکه ماویژگی   های  زیاد ی  به مدل داده ایم و مدل آن ها حفظ کرده  \\nاست.  \\n \\nماتریس سردرگمی را برای الگوریتم  K-nearest neighbors چند کلاسهمشاهده می کنیم.  \\n \\n \\nما شاهد  بسیاری از موارد  منف ی کاذب  (حملات از  دست  رفته) هستی م.  \\nشکل زیر بیشترین نوع حملاتی را که به درستی طبقه بندی نشده اند را  برای دسته بندی چند کلاسه   نشان  \\nمی دهد.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 52, 'page_label': '53'}, page_content='6- گامششم :  بکارگیری   یا   Deployment \\nپروتکلicmp  به طور قابل ملاحظه ای جهت نفوذ در شبکه استفاده شده است، بنابراین سیستمIDS  جهت\\nبرقراری امنیت باید توجه قابل قبولی به ترافیک هایی که از این پروتکل استفاده می کنند نمایید. \\nحملات  satan, nmap, ipsweep  از هر سه پروتکلicmp  و  tcp  و  udp  جهت نفوذ استفاده می کنند\\nبنابراین شناسایی آن ها سخت تر می باشد و سیستم  IDS باید توجه بیشتری به این نوع حملات کند \\nبیشترین نوع حملاتی که شناسایی نشده اند  Neptune  وSatan  هستند که این یکی از نقاط ضعف سیستم\\nامنیتی سازمان می باشد که باید در آینده تمهیداتی برای آن اندیشیده شود.  حمله   Neptune  حتی بعد از\\nبهبود هر دو الگوریتم ما  همچنان نرخ منفی کاذب زیادی دارد، که به نظر می رسد شناسایی این نوع حمله  \\nبرای هر دو الگوریتم ما نیز سخت می باشد. \\nیکی دیگر از مشکلاتی که در دسته بندی چند کلاسه مشاهده کردیم نرخ بالای ترافیک عادی بود که اشتباه  \\nبه عنوان حمله شناسایی شده بود.   که این نیز می تواند این نتیجه را ترافیک های  حمله به ترافیک عادی شبکه'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 52, 'page_label': '53'}, page_content='برای هر دو الگوریتم ما نیز سخت می باشد. \\nیکی دیگر از مشکلاتی که در دسته بندی چند کلاسه مشاهده کردیم نرخ بالای ترافیک عادی بود که اشتباه  \\nبه عنوان حمله شناسایی شده بود.   که این نیز می تواند این نتیجه را ترافیک های  حمله به ترافیک عادی شبکه  \\nشبیه هستند که این نیز یکی از مشکلاتی است که اغلب سیستم های تشخیص نفوذ از آن رنج می برند، که  \\nباعث می شود اعتماد به سیستم از بین برود.   در نتیجه سیستم تشخیص نفوذ سازمان باید در جهت برطرف  \\nشدن این مشکل تلاش نماید. \\nاما یکی از مهم ترین نتایج مدل سازی هنگام تست مدل های طبقه بندی دودویی مشاهده شد. برخی از  \\nحملات از جمله  guess_passwd  وwarezmaster  وproccesstable  وsnmpguess  وapache2  \\nکه در هنگام ارزیابی با داده هایvalidation، مدل برای شناشایی آن ها مشکلی نداشت و به راحتی شناسایی\\nمی شدند، اما هنگام تست با داده های آزمون بیشترین تعداد خطا را در هر دو الگوریتم به خود اختصاص  \\nدادند. که این امر نشان می دهد از جمله حملات ناشناخته هستند و با دیگر انواع حملات تفاوت های چشم  \\nگیری دارند   و یا به ترافیک عادی شبکه شباهت بسیاری دارند . بنابراین جزو حملاتی هستند که می توانند'),\n",
       " Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-30T11:13:06+03:30', 'author': 'myuser', 'moddate': '2025-12-30T11:13:06+03:30', 'source': 'my_pdf.pdf', 'total_pages': 53, 'page': 52, 'page_label': '53'}, page_content='دادند. که این امر نشان می دهد از جمله حملات ناشناخته هستند و با دیگر انواع حملات تفاوت های چشم  \\nگیری دارند   و یا به ترافیک عادی شبکه شباهت بسیاری دارند . بنابراین جزو حملاتی هستند که می توانند  \\nبرای امینت سازمان خطر آفرین باشند، در نتیجه سیستم  IDS  احتمالا در شناسایی آن ها با مشکل موجه\\nخواهد شد و سیستم  IDS جهت مقابله با آن ها باید تقویت شود')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c220780-3043-46c4-a6ea-926796ffcbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(text_documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7d6ba34-0b5b-4bb2-b9d9-c302a06d77be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: چند مورد از خسارت های ناشی از مشکل امنیتی در سازمان ها را بیان کنید؟\n",
      "Answer: کاهش اعتماد مشتریان، سرمایه گذاران و کارمندان، کاهش چشمگیر مشتریان سازمان، از دست رفتن اعتبار سازمان در میان رقبا، افزایش هزینه های سازمانی و کاهش سطح بهره وری و درآمد سازمان. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question: دیتاست NSL-KDDدر چه سالی عرضه شد؟\n",
      "Answer: دیتاست NSL-KDD در سال 2009 عرضه شد. \n",
      "\n",
      "\n",
      "Question: دیتاست NSL-KDD شامل چند نمونه ترافیک حمله و چند نمونه ترافیک عادی است؟\n",
      "Answer: دیتاست NSL-KDD  شامل 58630 مورد ترافیک حمله و 67343 نمونه ترافیک عادی است.  \n",
      "\n",
      "\n",
      "Question: مدل با استفاده از الگوریتم جنگل تصادفی به چه دقتی  بر روی داده های تست دست یافته است؟\n",
      "Answer: دقت مدل ما بر روی داده های تست  0.8035753892560884  می باشد. \n",
      "\n",
      "\n",
      "Question: مدل با استفاده از الگوریتم KNN به چه دقتی بر روی داده های تست دست یافته است؟\n",
      "Answer: دقت مدل ما بر روی داده های تست 0.8014904848511734 می باشد.  \n",
      "\n",
      "\n",
      "Question: یکی از مهم ترین نتایج مدل سازی هنگام تست مدل های طبقه بندی دودویی مشاهده شد چیست؟\n",
      "Answer: یکی از مهم ترین نتایج مدل سازی هنگام تست مدل های طبقه بندی دودویی این بود که برخی از حملات از جمله guess_passwd  وwarezmaster  وproccesstable  وsnmpguess  وapache2 که در هنگام ارزیابی با داده های validation، مدل برای شناشایی\n",
      "\n",
      "Question: یکی از مشکلاتی که در دسته بندی چند کلاسه مشاهده کردیم چیست؟\n",
      "Answer: یکی از مشکلاتی که در دسته بندی چند کلاسه مشاهده کردیم نرخ بالای ترافیک عادی بود که اشتباه به عنوان حمله شناسایی شده بود.  \n",
      "\n",
      "\n",
      "Question: الگوریتم جنگل تصادفی را توضیح بده؟\n",
      "Answer: جنگل تصادفی  (Random Forest) نوعی الگوریتم یادگیری گروهی  Ensemble Learning Algorithm)  است که چندین درخت تصمیم را برای پیشبینی ترکیب می کند. هر درخت تصمیم در جنگل  تصادفی بر روی یک زیر مجموعه تصادفی از داده های آموزشی\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"چند مورد از خسارت های ناشی از مشکل امنیتی در سازمان ها را بیان کنید؟\",\n",
    "    \"دیتاست NSL-KDDدر چه سالی عرضه شد؟\",\n",
    "    \"دیتاست NSL-KDD شامل چند نمونه ترافیک حمله و چند نمونه ترافیک عادی است؟\",\n",
    "    \"مدل با استفاده از الگوریتم جنگل تصادفی به چه دقتی  بر روی داده های تست دست یافته است؟\",\n",
    "    \"مدل با استفاده از الگوریتم KNN به چه دقتی بر روی داده های تست دست یافته است؟\",\n",
    "    \"یکی از مهم ترین نتایج مدل سازی هنگام تست مدل های طبقه بندی دودویی مشاهده شد چیست؟\",\n",
    "    \"یکی از مشکلاتی که در دسته بندی چند کلاسه مشاهده کردیم چیست؟\",\n",
    "    \"الگوریتم جنگل تصادفی را توضیح بده؟\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    retrieved_context = retriever.invoke(question)\n",
    "    formatted_prompt = prompt.format(context=retrieved_context, question=question)\n",
    "    response_from_model = apply_chat_template_and_response(formatted_prompt)\n",
    "    parsed_response = parser.parse(response_from_model)\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {parsed_response}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d383bf69-038a-450c-ba07-3052c7192602",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embedding_name = 'heydariAI/persian-embeddings'\n",
    "new_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=new_embedding_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed270ffe-972e-4f8c-bb56-33643cfc71f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vectorstore = DocArrayInMemorySearch.from_documents(text_documents, embedding=new_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4b3c9b1-aa78-4652-a8c3-709d8f0af71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: چند مورد از خسارت های ناشی از مشکل امنیتی در سازمان ها را بیان کنید؟\n",
      "Answer: کاهش اعتماد مشتریان، سرمایه گذاران و کارمندان، کاهش چشمگیر مشتریان سازمان، از دست رفتن اعتبار سازمان در میان رقبا و افزایش هزینه های سازمانی. \n",
      "\n",
      "\n",
      "Question: دیتاست NSL-KDDدر چه سالی عرضه شد؟\n",
      "Answer: دیتاست NSL-KDD در سال 2009 عرضه شد. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question: دیتاست NSL-KDD شامل چند نمونه ترافیک حمله و چند نمونه ترافیک عادی است؟\n",
      "Answer: دیتاست NSL-KDD شامل 58630 نمونه ترافیک حمله و 67343 نمونه ترافیک عادی است.  \n",
      "\n",
      "\n",
      "Question: مدل با استفاده از الگوریتم جنگل تصادفی به چه دقتی  بر روی داده های تست دست یافته است؟\n",
      "Answer: دقت مدل ما بر روی داده های تست برابر با 0.8035753892560884 است.  \n",
      "\n",
      "\n",
      "Question: مدل با استفاده از الگوریتم KNN به چه دقتی بر روی داده های تست دست یافته است؟\n",
      "Answer: دقت مدل بر روی داده های تست 0.8014904848511734 است.  \n",
      "\n",
      "\n",
      "Question: یکی از مهم ترین نتایج مدل سازی هنگام تست مدل های طبقه بندی دودویی مشاهده شد چیست؟\n",
      "Answer: همانطور که ملاحظه می کنید، دقت مدل ما بر روی داده های تست افت قابل ملاحظه ای داشته است. \n",
      "\n",
      "\n",
      "Question: یکی از مشکلاتی که در دسته بندی چند کلاسه مشاهده کردیم چیست؟\n",
      "Answer: احتمال خطا در طبقه بندی چند کلاسه بیشتر از دسته بندی دودویی می باشد.  \n",
      "\n",
      "\n",
      "Question: الگوریتم جنگل تصادفی را توضیح بده؟\n",
      "Answer: الگوریتم جنگل تصادفی (Random Forest) نوعی الگوریتم یادگیری گروهی است که چندین درخت تصمیم را برای پیشبینی ترکیب می کند. هر درخت تصمیم در جنگل تصادفی بر روی یک زیر مجموعه تصادفی از داده های آموزشی و یک زیر مجموعه\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"چند مورد از خسارت های ناشی از مشکل امنیتی در سازمان ها را بیان کنید؟\",\n",
    "    \"دیتاست NSL-KDDدر چه سالی عرضه شد؟\",\n",
    "    \"دیتاست NSL-KDD شامل چند نمونه ترافیک حمله و چند نمونه ترافیک عادی است؟\",\n",
    "    \"مدل با استفاده از الگوریتم جنگل تصادفی به چه دقتی  بر روی داده های تست دست یافته است؟\",\n",
    "    \"مدل با استفاده از الگوریتم KNN به چه دقتی بر روی داده های تست دست یافته است؟\",\n",
    "    \"یکی از مهم ترین نتایج مدل سازی هنگام تست مدل های طبقه بندی دودویی مشاهده شد چیست؟\",\n",
    "    \"یکی از مشکلاتی که در دسته بندی چند کلاسه مشاهده کردیم چیست؟\",\n",
    "    \"الگوریتم جنگل تصادفی را توضیح بده؟\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    retriever = new_vectorstore.as_retriever()\n",
    "    retrieved_context = retriever.invoke(question)\n",
    "    formatted_prompt = prompt.format(context=retrieved_context, question=question)\n",
    "    response_from_model = apply_chat_template_and_response(formatted_prompt)\n",
    "    parsed_response = parser.parse(response_from_model)\n",
    "\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {parsed_response}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec811b14-8382-4633-837f-741dfa6badbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
